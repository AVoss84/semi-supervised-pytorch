{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Imports and declarations\n",
    "%matplotlib inline\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "sys.path.append(\"../../semi-supervised\")\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Generative Model\n",
    "\n",
    "In this notebook we will run the Deep Generative Model as described in (Kingma 2014). The model builds on a standard variational autoencoder by adding label information during the inference. The main gist of the model is that we utilise label information when available, and marginalise over all labels when unavailable.\n",
    "\n",
    "Here we use a limited subset of MNIST to make training faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Load MNIST\n",
    "mnist = np.load(\"mnist.npz\")\n",
    "x_train, y_train = mnist[\"x_train\"], mnist[\"y_train\"]\n",
    "x_test, y_test = mnist[\"x_test\"], mnist[\"y_test\"]\n",
    "\n",
    "x, y = zip(*[(x_train[y_train == i][:10], y_train[y_train == i][:10]) for i in range(10)])\n",
    "x = np.array(x).reshape(-1, 28*28)\n",
    "y = np.array(y).reshape(-1)\n",
    "\n",
    "index = np.arange(100)\n",
    "np.random.shuffle(index)\n",
    "\n",
    "x = x[index]\n",
    "y = y[index]\n",
    "\n",
    "x = torch.from_numpy(x)\n",
    "y = torch.from_numpy(y)\n",
    "\n",
    "labelled = zip([x[:50], x[50:]], [y[:50], y[50:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.limitedmnist import LimitedMNIST\n",
    "from torchvision.datasets import MNIST\n",
    "from utils import generate_label, onehot\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "labels = np.arange(10)\n",
    "n = len(labels)\n",
    "\n",
    "# Load in data\n",
    "mnist_lab = LimitedMNIST('./', train=True, transform=torch.bernoulli, target_transform=onehot(n), digits=labels, fraction=0.0025)\n",
    "mnist_ulab = LimitedMNIST('./', train=True, transform=torch.bernoulli, target_transform=onehot(n), digits=labels, fraction=1.0)\n",
    "mnist_val = LimitedMNIST('./', train=False, transform=torch.bernoulli, target_transform=onehot(n), digits=labels)\n",
    "\n",
    "# Unlabelled data\n",
    "unlabelled = torch.utils.data.DataLoader(mnist_ulab, batch_size=100, shuffle=True, num_workers=2)\n",
    "\n",
    "# Validation data\n",
    "validation = torch.utils.data.DataLoader(mnist_val, batch_size=1000, shuffle=True, num_workers=2)\n",
    "\n",
    "# Labelled data\n",
    "labelled = torch.utils.data.DataLoader(mnist_lab, batch_size=100, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlMAAAB7CAYAAABQIQWaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBf4PboDJyJmGrLsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11383b390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, axarr = plt.subplots(1, 10, figsize=(10, 2))\n",
    "images, labels = next(iter(labelled))\n",
    "_, labels = torch.max(labels, 1)\n",
    "\n",
    "for i in range(10):\n",
    "    axarr[i].imshow(images[i].numpy().reshape(28, 28))\n",
    "    title = labels[i]\n",
    "    axarr[i].set_title(title)\n",
    "    axarr[i].axis(\"off\")\n",
    "    \n",
    "f.suptitle(\"Data samples after Bernoulli sampling\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We instantiate a Deep Generative Model by specifing the ratio between labelled and unlabelled data. We use variational inference to fit data to the model, like for the VAE. In this case, we also have label information so we use `VariationalInferenceWithLabels`. This objective is based on the ELBO objective described in (Kingma 2014).\n",
    "\n",
    "\n",
    "$$\\log p_{\\theta}(x, y) \\geq \\mathbb{E}_{q_{\\phi}(z|x, y)} [ \\log p_{\\theta}(x|y, z) + \\log p_{\\theta}(y) + \\log \\frac{p(z)}{q_{\\phi}(z|x, y)} ] = - \\mathcal{L}(x, y)$$\n",
    "\n",
    "Where the first term in the equation describes the likelihood function. The second can be viewed as a *prior* over the labels $y$, while the third part is just the KL-divergence we have already seen in VAEs. In this example, we choose a `discrete_uniform_prior` over the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepGenerativeModel(\n",
       "  (encoder): Encoder(\n",
       "    (hidden): ModuleList(\n",
       "      (0): Linear(in_features=794, out_features=500)\n",
       "    )\n",
       "    (sample): StochasticGaussian(\n",
       "      (mu): Linear(in_features=500, out_features=50)\n",
       "      (log_var): Linear(in_features=500, out_features=50)\n",
       "    )\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (hidden): ModuleList(\n",
       "      (0): Linear(in_features=60, out_features=500)\n",
       "    )\n",
       "    (reconstruction): Linear(in_features=500, out_features=784)\n",
       "    (output_activation): Sigmoid()\n",
       "  )\n",
       "  (classifier): Classifier(\n",
       "    (dense): Linear(in_features=784, out_features=500)\n",
       "    (logits): Linear(in_features=500, out_features=10)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models import DeepGenerativeModel\n",
    "from inference.loss import VariationalInferenceWithLabels\n",
    "\n",
    "# Numerical stability\n",
    "epsilon = 1e-8\n",
    "\n",
    "# DGM with a single hidden layer in both the encoder and decoder\n",
    "model = DeepGenerativeModel(ratio=len(mnist_ulab)/len(mnist_lab), dims=[28 * 28, n, 50, [500]])\n",
    "\n",
    "def binary_cross_entropy(r, x):\n",
    "    return torch.sum((x * torch.log(r + epsilon) + (1 - x) * torch.log((1 - r) + epsilon)), dim=-1)\n",
    "    \n",
    "    \n",
    "objective = VariationalInferenceWithLabels(binary_cross_entropy)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4, betas=(0.9, 0.999))\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model is a bit more complicated than for the standard VAE. We need to define two different cases based on whether the incoming data has labels or not. We use the definition for the ELBO given in the previous equation:\n",
    "\n",
    "$$- \\mathcal{L}(x, y) = \\mathbb{E}_{q_{\\phi}(z|x, y)} [ \\log p_{\\theta}(x|y, z) + \\log p_{\\theta}(y) + \\log \\frac{p(z)}{q_{\\phi}(z|x, y)} ]$$\n",
    "\n",
    "If labels are given, we calculate the ELBO along with the cross entropy.\n",
    "\n",
    "$$\\mathcal{L}(x, y) + \\alpha \\cdot \\mathbb{E}_{\\tilde{p}_l(x, y)}[- \\log q_{\\phi}(y|x)]$$\n",
    "\n",
    "However, if no labels are given, we must instead sum over all of the labels. In order to keep the equations balanced, we are required to calculate the entropy.\n",
    "\n",
    "$$\\sum_y q_{\\phi}(y|x)(- \\mathcal{L}(x, y)) + \\mathcal{H}(q_{\\phi}(y|x)) = -\\mathcal{U}(x)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "def custom_logger(d):\n",
    "    x, y = next(iter(validation))\n",
    "    _, y_logits = torch.max(model.classifier(Variable(x)), 1)\n",
    "    _, y = torch.max(y, 1)\n",
    "\n",
    "    acc = torch.sum(y_logits.data == y)/len(y)\n",
    "    d[\"Accuracy\"] = acc\n",
    "    \n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trainers import DGMTrainer\n",
    "trainer = DGMTrainer(model, objective, optimizer, logger=custom_logger, cuda=False)\n",
    "#trainer.train(labelled, unlabelled, 25+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## M1 + M2\n",
    "\n",
    "In the previous notebook we trained VAE on the same data, this means that we can construct the stacked DGM M1+M2 model. We train it the same way as for a regular DGM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackedDeepGenerativeModel(\n",
       "  (encoder): Encoder(\n",
       "    (hidden): ModuleList(\n",
       "      (0): Linear(in_features=60, out_features=500)\n",
       "    )\n",
       "    (sample): StochasticGaussian(\n",
       "      (mu): Linear(in_features=500, out_features=50)\n",
       "      (log_var): Linear(in_features=500, out_features=50)\n",
       "    )\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (hidden): ModuleList(\n",
       "      (0): Linear(in_features=60, out_features=500)\n",
       "    )\n",
       "    (reconstruction): Linear(in_features=500, out_features=784)\n",
       "    (output_activation): Sigmoid()\n",
       "  )\n",
       "  (classifier): Classifier(\n",
       "    (dense): Linear(in_features=50, out_features=500)\n",
       "    (logits): Linear(in_features=500, out_features=10)\n",
       "  )\n",
       "  (features): VariationalAutoencoder(\n",
       "    (encoder): Encoder(\n",
       "      (hidden): ModuleList(\n",
       "        (0): Linear(in_features=784, out_features=500)\n",
       "      )\n",
       "      (sample): StochasticGaussian(\n",
       "        (mu): Linear(in_features=500, out_features=50)\n",
       "        (log_var): Linear(in_features=500, out_features=50)\n",
       "      )\n",
       "    )\n",
       "    (decoder): Decoder(\n",
       "      (hidden): ModuleList(\n",
       "        (0): Linear(in_features=50, out_features=500)\n",
       "      )\n",
       "      (reconstruction): Linear(in_features=500, out_features=784)\n",
       "      (output_activation): Sigmoid()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models import VariationalAutoencoder, StackedDeepGenerativeModel\n",
    "\n",
    "vae = VariationalAutoencoder([28*28, 50, [500]])\n",
    "stacked_dgm = StackedDeepGenerativeModel([28*28, 10, 50, [500]], len(mnist_ulab)/len(mnist_lab), vae)\n",
    "stacked_dgm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'Unlabelled loss': 608.5753784179688, 'Labelled loss': 710.7869873046875, 'Accuracy': 0.11}\n",
      "{'epoch': 1, 'Unlabelled loss': 607.5569458007812, 'Labelled loss': 708.7993774414062, 'Accuracy': 0.112}\n",
      "{'epoch': 2, 'Unlabelled loss': 607.7408447265625, 'Labelled loss': 712.1246337890625, 'Accuracy': 0.095}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-23:\n",
      "Process Process-24:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jesperwohlerthansen/miniconda3/envs/vision/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/jesperwohlerthansen/miniconda3/envs/vision/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/jesperwohlerthansen/miniconda3/envs/vision/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/jesperwohlerthansen/miniconda3/envs/vision/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/jesperwohlerthansen/miniconda3/envs/vision/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 36, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/Users/jesperwohlerthansen/miniconda3/envs/vision/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 36, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/Users/jesperwohlerthansen/miniconda3/envs/vision/lib/python3.6/multiprocessing/queues.py\", line 343, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/Users/jesperwohlerthansen/miniconda3/envs/vision/lib/python3.6/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/Users/jesperwohlerthansen/miniconda3/envs/vision/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/Users/jesperwohlerthansen/miniconda3/envs/vision/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Users/jesperwohlerthansen/miniconda3/envs/vision/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/Users/jesperwohlerthansen/miniconda3/envs/vision/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-521b3778bf64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDGMTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstacked_dgm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_logger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabelled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munlabelled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/PycharmProjects/semi-supervised-pytorch/semi-supervised/trainers.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, labelled, unlabelled, n_epochs)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabelled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munlabelled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m                 \u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_calculate_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m                 \u001b[0mL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_calculate_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/semi-supervised-pytorch/semi-supervised/trainers.py\u001b[0m in \u001b[0;36m_calculate_loss\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;31m# Compute lower bound (the same as -L)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mreconstruction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mlog_likelihood\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkl_divergence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_prior_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreconstruction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# - L(x, y)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/vision/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/semi-supervised-pytorch/semi-supervised/inference/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, r, x, y, latent)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \"\"\"\n\u001b[1;32m    101\u001b[0m         \u001b[0mlog_prior_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_standard_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mlog_likelihood\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreconstruction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0mkl_divergence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlog_standard_gaussian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlog_gaussian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_var\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_var\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlatent\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-b236514fe31b>\u001b[0m in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(r, x)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer = DGMTrainer(stacked_dgm, objective, optimizer, logger=custom_logger, cuda=False)\n",
    "trainer.train(labelled, unlabelled, 25+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation\n",
    "\n",
    "Here you can optionally enable the use of `visdom` to visualise the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_visdom = True\n",
    "\n",
    "if use_visdom:\n",
    "    import visdom\n",
    "    vis = visdom.Visdom()\n",
    "\n",
    "class Visualiser():\n",
    "    def __init__(self):\n",
    "        self.loss = vis.line(X=np.array([0]), Y=np.array([0]), opts=dict(title=\"Training Loss\", xlabel=\"Epoch\"))\n",
    "        self.acc  = vis.line(X=np.array([0]), Y=np.array([0]), opts=dict(title=\"Accuracy\", xlabel=\"Epoch\"))\n",
    "\n",
    "    def update_loss(self, L, U):\n",
    "        vis.updateTrace(X=np.array([epoch]), Y=L.data.numpy(), win=self.loss, name=\"Labelled\")\n",
    "        vis.updateTrace(X=np.array([epoch]), Y=U.data.numpy(), win=self.loss, name=\"Unlabelled\")\n",
    "        \n",
    "    def update_accuracy(self, model):\n",
    "        accuracy = []\n",
    "        for x, y in validation:\n",
    "            _, prediction = torch.max(model.classifier(Variable(x)), 1)\n",
    "            _, y = torch.max(y, 1)\n",
    "\n",
    "            accuracy += [torch.mean((prediction.data == y).float())]\n",
    "\n",
    "        vis.updateTrace(X=np.array([epoch]), Y=np.array([np.mean(accuracy)]), win=self.acc)\n",
    "        \n",
    "    def update_images(self, model):\n",
    "        x, y = next(iter(validation))\n",
    "        input = Variable(x[:5])\n",
    "        label = Variable(y[:5].type(torch.FloatTensor))\n",
    "        x_hat, *_ = model(input, label)\n",
    "        images = x_hat.data.numpy().reshape(-1, 1, 28, 28)\n",
    "\n",
    "        vis.images(images, opts=dict(width=5*64, height=64, caption=\"Sample epoch {}\".format(epoch)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Controlling which dataloaders to use, we gather the losses into a single combined loss that we can backpropagate.\n",
    "\n",
    "$$\\mathcal{J}^{\\alpha} = \\mathcal{L}^{\\alpha} + \\mathcal{U}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "trainer = DGMTrainer(model, objective, optimizer)\n",
    "visual = Visualiser()\n",
    "\n",
    "for epoch in range(1001):\n",
    "    L, U = trainer.train(labelled, unlabelled)\n",
    "        \n",
    "    if use_visdom:\n",
    "        # Plot the last L and U of the epoch\n",
    "        visual.update_loss(L, U)\n",
    "        visual.update_accuracy(model)\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            visual.update_images(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After performing training, your plots should look something like this:\n",
    "    \n",
    "![](../images/visdom-dgm.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
