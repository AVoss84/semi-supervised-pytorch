{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       ".output_png {\n",
       "    display: table-cell;\n",
       "    text-align: center;\n",
       "    vertical-align: middle;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imports and declarations\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.rcParams[\"image.cmap\"] = \"binary_r\"\n",
    "import sys\n",
    "sys.path.append(\"../../semi-supervised\")\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "cuda = torch.cuda.is_available()\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"\"\"\n",
    "<style>\n",
    ".output_png {\n",
    "    display: table-cell;\n",
    "    text-align: center;\n",
    "    vertical-align: middle;\n",
    "}\n",
    "</style>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational AutoEncoder\n",
    "\n",
    "This notebook shows how to use a Variational AutoEncoder to model the data distribution over MNIST-digits $p(x)$. We will then learn a latent distribution $q_{\\theta}(z \\mid x)$ based on the digits. The M1 model in (Kingma 2014) describes the semi-supervised classifier as mapping latent representations to their label using a classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten_bernoulli = lambda img: transforms.ToTensor()(img).view(-1).bernoulli()\n",
    "\n",
    "mnist = datasets.MNIST('./', train=True, download=True, transform=flatten_bernoulli)\n",
    "mnist_val = datasets.MNIST('./', train=False, download=True, transform=flatten_bernoulli)\n",
    "\n",
    "unlabelled = torch.utils.data.DataLoader(mnist, batch_size=100, shuffle=True, num_workers=2)\n",
    "validation = torch.utils.data.DataLoader(mnist_val, batch_size=100, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlMAAAB7CAYAAABQIQWaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11c594860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, axarr = plt.subplots(1, 10, figsize=(10, 2))\n",
    "images, labels = next(iter(unlabelled))\n",
    "\n",
    "for i in range(10):\n",
    "    axarr[i].imshow(images[i].numpy().reshape(28, 28))\n",
    "    axarr[i].set_title(labels[i])\n",
    "    axarr[i].axis(\"off\")\n",
    "    \n",
    "f.suptitle(\"Data samples after Bernoulli transform\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variational autoencoder is defined in terms of its input dimensionality along with the dimensionality of the latent space. In this example we have exactly one hidden layer both the encoder and decoder with 128 neurons. In order to train the model, we use variational inference by fitting a variational distribution $q(z | X)$ to the encoder. The full objective is given by: \n",
    "\n",
    "$${\\mathcal {L}}(\\phi,\\theta, X) = D_{KL}(q_{\\phi}( z | X ) \\ || \\ p(z))-\\mathbb {E}_{q_{\\phi }(z |X )}\\log p_{\\theta }(X | z )$$\n",
    "\n",
    "Where $\\phi$ and $\\theta$ are parameters of the encoder and decoder network respectively. The objective means that we want to make maximise the models ability to recreate the input given a learned latent representation $x$ while keeping $q(z | X)$ similar to some known distribution.\n",
    "\n",
    "For this problem we choose $q(z | X)$ to be similar to a standard normal distribution by using `kl_divergence_normal` and we measure the pixelwise binary cross entropy as our likelihood function. This leads to the model and loss function as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VariationalAutoencoder (\n",
       "  (encoder): Encoder (\n",
       "    (hidden): ModuleList (\n",
       "      (0): Linear (784 -> 128)\n",
       "    )\n",
       "    (sample): StochasticGaussian (\n",
       "      (mu): Linear (128 -> 32)\n",
       "      (log_var): Linear (128 -> 32)\n",
       "    )\n",
       "  )\n",
       "  (decoder): Decoder (\n",
       "    (hidden): ModuleList (\n",
       "      (0): Linear (32 -> 128)\n",
       "    )\n",
       "    (reconstruction): Linear (128 -> 784)\n",
       "    (output_activation): Sigmoid ()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.vae import VariationalAutoencoder\n",
    "from inference.loss import VariationalInference, kl_divergence_normal\n",
    "\n",
    "model = VariationalAutoencoder([28*28, 32, [128]])\n",
    "\n",
    "if cuda: model = model.cuda()\n",
    "\n",
    "def binary_cross_entropy(r, x):\n",
    "    return F.binary_cross_entropy(r, x, size_average=False)\n",
    "    \n",
    "objective = VariationalInference(binary_cross_entropy, kl_divergence_normal)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-5)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 loss: 28338.348\n",
      "Epoch: 5 loss: 18254.439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-21:\n",
      "Process Process-22:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jesperwohlerthansen/miniconda3/envs/torch35/lib/python3.5/multiprocessing/process.py\", line 254, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/jesperwohlerthansen/miniconda3/envs/torch35/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/jesperwohlerthansen/miniconda3/envs/torch35/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/Users/jesperwohlerthansen/miniconda3/envs/torch35/lib/python3.5/multiprocessing/process.py\", line 254, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/jesperwohlerthansen/miniconda3/envs/torch35/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/Users/jesperwohlerthansen/miniconda3/envs/torch35/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/jesperwohlerthansen/miniconda3/envs/torch35/lib/python3.5/multiprocessing/queues.py\", line 343, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/Users/jesperwohlerthansen/miniconda3/envs/torch35/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/Users/jesperwohlerthansen/miniconda3/envs/torch35/lib/python3.5/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/Users/jesperwohlerthansen/miniconda3/envs/torch35/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/Users/jesperwohlerthansen/miniconda3/envs/torch35/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/Users/jesperwohlerthansen/miniconda3/envs/torch35/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-c4a0d838f5aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/torch35/lib/python3.5/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "for epoch in range(50):\n",
    "    for u, _ in unlabelled:\n",
    "        u = Variable(u)\n",
    "\n",
    "        if cuda: u = u.cuda()\n",
    "\n",
    "        reconstruction, (_, z_mu, z_log_var) = model(u)\n",
    "        # Equation 3\n",
    "        L = objective(reconstruction, u, z_mu, z_log_var)\n",
    "\n",
    "        L.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "        l = L.data[0]\n",
    "        print(\"Epoch: {0:} loss: {1:.3f}\".format(epoch, l))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification\n",
    "\n",
    "Now that we have constructed a distribution $p(z | x)$ and are able to transform our data $x$ into latent representation $z$, we can perform classification. In Kingma 2014, it is suggested to use an SVM. We will instead use a simple multilayer perceptron, which should work as the latent space is of lower dimensionality than the input space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "classifier = nn.Sequential(\n",
    "    nn.Linear(32, 32),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(32, 10),\n",
    "    nn.Softmax())\n",
    "\n",
    "optimizer = torch.optim.Adam(classifier.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(50):\n",
    "    for x, y in unlabelled:\n",
    "\n",
    "        x = Variable(x)\n",
    "        y = Variable(y)\n",
    "\n",
    "        if cuda:\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "\n",
    "        _, (z, _, _) = model(x)\n",
    "        logits = classifier(z)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        # Check validation accuracy\n",
    "        accuracy = []\n",
    "        for x, y in validation:\n",
    "            _, (z, _, _) = model(Variable(x))\n",
    "            logits = classifier(z)\n",
    "            _, prediction = torch.max(classifier(z), 1)\n",
    "\n",
    "            accuracy += [torch.mean((prediction.data == y).float())]\n",
    "\n",
    "        print(\"Epoch: {0:} loss: {1:.3f}, accuracy: {2:.3f}\".format(epoch, loss.data[0], np.mean(accuracy)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get around 90% accuracy from just running it for a few epochs. It is expected as we get more unsupervised data, the model will perform better. However, being an extremely simple model, we can never achieve great performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
